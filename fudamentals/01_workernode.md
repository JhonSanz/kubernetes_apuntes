Docker es uno de los software mas populares para manejar contenedores. Sin embargo, debido a la especificidad de sus funciones, docker no fue dise침ado para ser una soluci칩n enterprise ya que:

- Single host: Docker corre sobre un host, y sobre este monta los contenedores, lo cu치l es un problema si hay un n칰mero de contenedores cuya ejecuci칩n supere los recursos del sistema. En este caso, linux evitar치 que se creen contenedores nuevos y tendremos problemas para que nuestra aplicaci칩n se ejecute correctamente
- No ofrece autoscalling: Al aumentar el tr치fico que llega a nuestra aplicaci칩n, no hay manera de que docker pueda crecer autom치ticamente en recursos basado en condiciones espec칤ficas, por ejemplo, el uso de cpu o memoria en nuestra VPS 
- No ofrece autohealling: Al haber una se침al negativa de healty en uno de nuestros contenedores, no hay manera de asegurar que el contenedor va a morir y se va a crear uno nuevo
- No ofrece los est치ndares enterprise: Docker est치 pensado para correr servicios de forma aislada (lo cual es muy bueno), pero debido a eso mismo se escapan los detalles de firewall, load balancing etc. Por lo cual, si necesitaramos crecer nuestra aplicaci칩n, la 칰nica manera ser칤a incrementar los recursos del host, lo cual no es necesariamente lo mejor.

Todo esto est치 칤ntimamente relacionado con la arquitectura de microservicios. Imaginemos una aplicaci칩n que tiene un servidor de backend, uno de mensajes y uno de reportes. Si todos estuvieran en el mismo VPS estar칤amos quemando dinero, ya que no necesariamente los tres servidores ser칤an los responsables del consumo de CPU y memoria

Es por esto que tener los tres separados es clave, y aqui es donde kubernetes brilla. Si tenemos los tres separados, y el trafico aumenta en solo uno de ellos, lo l칩gico es que 칰nicamente ese servicio sea el que debe crecer. Este simple hecho hace que cobre importancia y sentido el loadbalancing y el autoscalling. Nuesrto backend recibir치 mucho mas tr치fico que los otros dos servicios, entonces este ser치 el que debe crecer.


# KUBELET


Kubernetes es una soluci칩n agn칩stica al software de contenedores que se utilice, es decir, existen canitdad de soluciones alternativas a docker, y kubernetes funciona con cada una de ellas. 

Dicho esto, aqu칤 entra el concepto de **container runtime**, y en terminos generales 

> Un runtime de contenedores es el software responsable de ejecutar los contenedores. Proporciona las funcionalidades b치sicas necesarias para crear, ejecutar y gestionar contenedores. Algunos ejemplos de runtimes de contenedores incluyen Docker, containerd y CRI-O. 

> En Kubernetes, el runtime de contenedores es una pieza clave del ecosistema, ya que es responsable de ejecutar los contenedores definidos en los Pods. Kubernetes utiliza la Container Runtime Interface (CRI) para interactuar con los runtimes de contenedores, lo que permite a Kubernetes soportar m칰ltiples tipos de runtimes.

Dicho esto, es hora de introducir el concepto de **kubelet**. Kubelet es la pieza dentro de kubernetes que interact칰a con el runtime de contenedores, **a trav칠s del CRI (container runtime interface)** la cu치l es la pieza fundamental que permite utilziar cualquier runtime que se acomode a esta interfaz. 

"Kubelet es un agente que corre en cada nodo del cl칰ster de Kubernetes y se asegura de que los contenedores est칠n corriendo en un Pod."

Enfatizar que Kubelet no s칩lo interact칰a con el runtime, sino tambi칠n aplica las configuraciones especificadas en los Pods.

![kubelet1](../media/kubelet1.png)

Entonces kubelet una vez conectado podr치 gestionar los contenedores, por ejemplo las tareas b치sicas como *iniciar, detener, reinciar y monitorear*, entre muchas otras cosas. Lo importante es enteder que kubelet se comunica con los contenedores y los gestiona (a traves del CRI)

# Pod

El siguiente paso l칩gico es analizar los Pods. Sabemos que kubelet tiene control sobre la gesti칩n de los contenedores, pero 쯗칩nde est치n los contenedores?. Bueno, pues nada nuevo, el runtime se encarga de toda la operaci칩n sobre los contenedores, eso est치 claro. Lo importante es que kubernetes ahora es el que se encarga de gestionar las operaciones por medio de kubelet, y a su vez para darle contexto kubernetes agrupa los contenedores en Pods.

Un pod puede tener uno o varios contenedores, la documentaci칩n lo define como un "host l칩gico", algo as칤 como tener un host de docker que corre unos contenedores cualquiera.

Algo **muy importante** es que los contenedores dentro de un pod comparten direcci칩n Ip y puerto, y pueden encontrarse entre ellos a trav칠s de localhost.

Tambi칠n **importante** es que los contenedores dentro de un pod tienen acceso a vol칰menes compartidos.

Ok, muy interesante. Ahora, recordando una vez mas que kubelet es el encargado de manejar los contenedores, y que kubernetes "asignar치" los contenedores a alg칰n Pod, veamos como es el proceso en su forma mas b치sica:

> kubectl apply -f https://k8s.io/examples/pods/simple-pod.yaml

Este lindo comando crear치 un pod simple con una imagen de nginx

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
```

Lo divertido es que **nunca crearemos los pods de esta manera** 游뱎. Seg칰n la documentaci칩n "los pods est치n dise침ados para ser relativamente efimeros" lo cual implica asumir una responsabilidad innecesaria al crearlos manualmente, ya que nos volver칤amos locos para gestionar un cluster con una cantidad considerable de nodos.

Entonces como siempre, lo mejor es apuntar a la **simplicidad** y automatizaci칩n. Por eso elegimos el enfoque **declarativo**, es decir, escrbiendo el comportamiento deseado en un bello archivo .yaml

### Pods Controllers

Aqu칤 es donde viene algo llamado Pods Controllers. Y para no perder la cabeza, son simplemente **formas distintas de crear nuestros pods**. Kubernetes asumi칩 el quebradero de cabeza y lleg칩 a los siguientes controladores:

- **ReplicaSet**: Garantiza que un n칰mero espec칤fico de r칠plicas de un Pod est칠 en funcionamiento en todo momento. Si el n칰mero de r칠plicas cae por debajo del especificado, ReplicaSet crea autom치ticamente nuevos Pods para restaurar el n칰mero deseado.

- **Deployment**: Proporciona actualizaciones declarativas para tus aplicaciones, permitiendo realizar despliegues y rollbacks de manera controlada. Un Deployment administra un ReplicaSet subyacente para gestionar el n칰mero de r칠plicas de los Pods.

- **StatefulSet**: Proporciona garant칤as sobre el orden y la estabilidad de los Pods, especialmente en aplicaciones con estado como bases de datos. Cada Pod en un StatefulSet tiene un identificador 칰nico y un orden definido, lo que facilita la gesti칩n de la persistencia de datos.

- **DaemonSet**: Garantiza que un Pod est칠 en funcionamiento en cada nodo del cl칰ster (o en nodos seleccionados). Es 칰til para tareas como la recolecci칩n de logs o la supervisi칩n del cl칰ster.

- **Job y CronJob**: Ejecutan tareas de manera puntual o peri칩dica. Los Jobs se utilizan para tareas que se ejecutan una sola vez, mientras que los CronJobs se utilizan para tareas que se ejecutan de forma peri칩dica seg칰n un cronograma.


Evidentemente cada uno tiene sus casos de uso y especificidades, las cuales se interiorizar치n con el tiempo y algo de sufrimiento. Luego veremos esto con mas detalle


# Kube proxy

Como mencionamos anteriormente, un pod puede albergar simultaneamente varios contenedores. Y a su vez varios pod pueden vivir en un mismo Nodo. Este escenario es el ideal para pensar en una red.

Algo **importante** que hay que recordar siempre, es que un pod puede entenderse como un **host virtual**, por lo que, los contenedores que vivan dentro de el van a compartir direcci칩n IP. Esto significa que al igual que con docker, lo que hacemos es exponer algunos puertos para que puedan ser utilizados desde afuera del pod, pero conservando la misma direcci칩n IP. Finalmente, para comunicar los contenedores dentro del pod se utiliza **localhost**.

Lo importante ahora es entender que **dentro del nodo vive kube proxy** el cual se encarga de mantener las funciones de red en los nodos, as칤 como para los servicios que exponen estos Pods hacia el exterior.

- **Balaceo de Carga**: Kube-proxy gestiona el tr치fico de red hacia los servicios expuestos por los Pods, distribuyendo de manera equitativa las solicitudes entrantes entre las r칠plicas de los Pods que forman el servicio.

- **Servicio de Proxy**: Act칰a como un proxy de red para los servicios de Kubernetes, exponiendo una IP virtual 칰nica para cada servicio. Esto permite que los servicios sean accesibles de manera uniforme desde dentro y fuera del cl칰ster.

- **Network Address Translation (NAT)**: Kube-proxy configura reglas NAT para redirigir el tr치fico de red desde la IP virtual del servicio hacia las IP reales de los Pods que componen ese servicio.

- **Gesti칩n de Servicios**: Asegura que los servicios est칠n disponibles y se comuniquen correctamente dentro del cl칰ster, manteniendo la conectividad y la resoluci칩n de nombres de servicio.

# Ingress

Es la pieza responsable de manejar el acceso externo hacia nuestros servicios de kubernetes. En este punto es muy com칰n ver a nginx para manejar el balanceo de carga externo, certificados SSL y routing basado en reglas espec칤ficas (entre muchas otras cosas, seguridad etc...)


# Worker node